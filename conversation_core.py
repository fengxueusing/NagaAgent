import logging,os,asyncio # æ—¥å¿—ä¸ç³»ç»Ÿ
from datetime import datetime # æ—¶é—´
from config import LOG_DIR,DEEPSEEK_API_KEY,DEEPSEEK_MODEL,TEMPERATURE,MAX_TOKENS,get_current_datetime,THEME_ROOTS,DEEPSEEK_BASE_URL,NAGA_SYSTEM_PROMPT,VOICE_ENABLED # é…ç½®
from summer.summer_faiss import faiss_recall,faiss_add,faiss_fuzzy_recall # faissæ£€ç´¢ä¸å…¥åº“
from mcp_manager import get_mcp_manager, remove_tools_filter, HandoffInputData # å¤šåŠŸèƒ½ç®¡ç†
from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX # handoffæç¤ºè¯
from mcpserver.agent_playwright_master import PlaywrightAgent, extract_url # å¯¼å…¥æµè§ˆå™¨ç›¸å…³ç±»
from openai import OpenAI,AsyncOpenAI # LLM
import difflib # æ¨¡ç³ŠåŒ¹é…
import sys,json,traceback
from voice.voice_config import config as vcfg # è¯­éŸ³é…ç½®
from voice.voice_handler import VoiceHandler # è¯­éŸ³å¤„ç†
import time # æ—¶é—´æˆ³æ‰“å°
from summer.memory_manager import MemoryManager  # æ–°å¢
from mcpserver.mcp_registry import register_all_handoffs # å¯¼å…¥æ‰¹é‡æ³¨å†Œæ–¹æ³•
from quick_model_manager import QuickModelManager  # æ–°å¢
now=lambda:time.strftime('%H:%M:%S:')+str(int(time.time()*1000)%10000) # å½“å‰æ—¶é—´
_builtin_print=print
print=lambda *a,**k:sys.stderr.write('[print] '+(' '.join(map(str,a)))+'\n')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger("NagaConversation")

_MCP_HANDOFF_REGISTERED=False

class NagaConversation: # å¯¹è¯ä¸»ç±»
 def __init__(s):
  s.mcp=get_mcp_manager()
  s.messages=[]
  s.dev_mode=False
  s.voice=VoiceHandler() if vcfg.ENABLED else None
  s.client=OpenAI(api_key=DEEPSEEK_API_KEY,base_url=DEEPSEEK_BASE_URL.rstrip('/')+'/')
  s.async_client=AsyncOpenAI(api_key=DEEPSEEK_API_KEY,base_url=DEEPSEEK_BASE_URL.rstrip('/')+'/')
  s.memory = MemoryManager()  # æ–°å¢ï¼šåˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨
  s.compat_mode = False # æ–°å¢ï¼šå…¼å®¹å‡çº§æ¨¡å¼çŠ¶æ€
  
  # æ–°å¢ï¼šå¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨
  try:
    s.quick_model = QuickModelManager()
    logger.info("å¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
  except Exception as e:
    logger.warning(f"å¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    s.quick_model = None
  
  # æ–°å¢ï¼šæ ‘çŠ¶æ€è€ƒç³»ç»Ÿ
  try:
    from thinking import TreeThinkingEngine
    s.tree_thinking = TreeThinkingEngine(api_client=s, memory_manager=s.memory)
    logger.info("æ ‘çŠ¶å¤–ç½®æ€è€ƒç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
  except Exception as e:
    logger.warning(f"æ ‘çŠ¶æ€è€ƒç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    s.tree_thinking = None
  
  # æ–°å¢ï¼šæ€§æ ¼ç³»ç»Ÿ
  s.current_personality = "DEFAULT"  # å½“å‰æ€§æ ¼ä»£ç 
  s.personality_config = {}  # å½“å‰æ€§æ ¼é…ç½®
  s.base_system_prompt = NAGA_SYSTEM_PROMPT  # ä¿å­˜åŸå§‹ç³»ç»Ÿæç¤ºè¯
  
  global _MCP_HANDOFF_REGISTERED
  if not _MCP_HANDOFF_REGISTERED:
    try:
      logger.info("å¼€å§‹æ³¨å†Œæ‰€æœ‰Agent handoffå¤„ç†å™¨...")
      register_all_handoffs(s.mcp) # ä¸€é”®æ³¨å†Œæ‰€æœ‰Agent
      logger.info("æˆåŠŸæ³¨å†Œæ‰€æœ‰Agent handoffå¤„ç†å™¨")
      _MCP_HANDOFF_REGISTERED=True
    except Exception as e:
      logger.error(f"æ³¨å†ŒAgent handoffå¤„ç†å™¨å¤±è´¥: {e}")
      traceback.print_exc(file=sys.stderr)
 def save_log(s,u,a): # ä¿å­˜å¯¹è¯æ—¥å¿—
  if s.dev_mode:return # å¼€å‘è€…æ¨¡å¼ä¸å†™æ—¥å¿—
  d=datetime.now().strftime('%Y-%m-%d')
  t=datetime.now().strftime('%H:%M:%S')
  f=os.path.join(LOG_DIR,f'{d}.txt')
  with open(f,'a',encoding='utf-8')as w:w.write(f'-'*50+f'\næ—¶é—´: {d} {t}\nç”¨æˆ·: {u}\nå¨œè¿¦: {a}\n\n')
 def normalize_theme(s,raw): # ä¸»é¢˜å½’ä¸€åŒ–
  seg=raw.split('/')
  root=difflib.get_close_matches(seg[0],THEME_ROOTS.keys(),n=1,cutoff=0.6)
  root=root[0] if root else list(THEME_ROOTS.keys())[0]
  if len(seg)>1:
    sub=difflib.get_close_matches(seg[1],THEME_ROOTS[root],n=1,cutoff=0.6)
    sub=sub[0] if sub else THEME_ROOTS[root][0]
    return '/'.join([root,sub]+seg[2:])
  return root
 def get_theme_and_level(s, u): # LLMä¸»é¢˜+åˆ†å±‚åˆ¤å®š
  r = s.client.chat.completions.create(
      model=DEEPSEEK_MODEL,
      messages=[
          {"role": "system", "content": "è¯·ç”¨/åˆ†éš”è¾“å‡ºæœ¬è½®å¯¹è¯ä¸»é¢˜æ ‘ï¼ˆå¦‚'ç§‘æŠ€/äººå·¥æ™ºèƒ½/å¤§æ¨¡å‹'ï¼‰ï¼Œå¹¶åˆ¤æ–­å†…å®¹åº”å½’ä¸ºå“ªç±»è®°å¿†å±‚çº§ï¼ˆcore/archival/long_term/short_termï¼‰ã€‚\nè¯·ç”¨å¦‚ä¸‹JSONæ ¼å¼è¿”å›ï¼š{\"theme\": \"ä¸»é¢˜æ ‘\", \"level\": \"core/archival/long_term/short_term\"}ï¼Œä¸è¦å¤šä½™å†…å®¹ã€‚"},
          {"role": "user", "content": u}
      ],
      temperature=0.2,
      max_tokens=40
  ).choices[0].message.content
  try:
      result = json.loads(r)
      theme = s.normalize_theme(result.get('theme',''))
      level = result.get('level','').strip().lower()
      if level not in ['core','archival','long_term','short_term']:
          level = None
      return theme, level
  except Exception:
      # å…œåº•ï¼šåªç”¨åŸæœ‰ä¸»é¢˜åˆ¤å®šï¼Œåˆ†å±‚ç”¨è§„åˆ™
      theme = s.normalize_theme(u)
      text = u
      if 'èº«ä»½' in text:
          level = 'core'
      elif 'é‡è¦äº‹ä»¶' in text:
          level = 'archival'
      elif len(text) > 30:
          level = 'long_term'
      else:
          level = 'short_term'
      return theme, level
 def get_theme(s, u): # å…¼å®¹æ¥å£ï¼Œå†…éƒ¨ç”¨get_theme_and_level
  theme, _ = s.get_theme_and_level(u)
  return theme
 async def process(s,u):
  import json # ä¿è¯jsonåœ¨æœ¬åœ°ä½œç”¨åŸŸå¯ç”¨
  try:
   # devmodeä¼˜å…ˆåˆ¤æ–­
   if u.strip()=="#devmode":
    s.dev_mode=True
    yield ("å¨œè¿¦","å·²è¿›å…¥å¼€å‘è€…æ¨¡å¼ï¼Œåç»­å¯¹è¯ä¸å†™å…¥å‘é‡åº“");return
   
   # æ ‘çŠ¶æ€è€ƒç³»ç»Ÿæ§åˆ¶æŒ‡ä»¤
   if u.strip().startswith("#tree"):
    if s.tree_thinking is None:
      yield ("å¨œè¿¦", "æ ‘çŠ¶æ€è€ƒç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨è¯¥åŠŸèƒ½");return
    
    command = u.strip().split()
    if len(command) == 2:
      if command[1] == "on":
        s.tree_thinking.enable_tree_thinking(True)
        yield ("å¨œè¿¦", "ğŸŒ³ æ ‘çŠ¶å¤–ç½®æ€è€ƒç³»ç»Ÿå·²å¯ç”¨");return
      elif command[1] == "off":
        s.tree_thinking.enable_tree_thinking(False)
        yield ("å¨œè¿¦", "æ ‘çŠ¶æ€è€ƒç³»ç»Ÿå·²ç¦ç”¨ï¼Œæ¢å¤æ™®é€šå¯¹è¯æ¨¡å¼");return
      elif command[1] == "status":
        status = s.tree_thinking.get_system_status()
        enabled_status = "å¯ç”¨" if status["enabled"] else "ç¦ç”¨"
        yield ("å¨œè¿¦", f"ğŸŒ³ æ ‘çŠ¶æ€è€ƒç³»ç»ŸçŠ¶æ€ï¼š{enabled_status}\nå½“å‰ä¼šè¯ï¼š{status['current_session']}\nå†å²ä¼šè¯æ•°ï¼š{status['total_sessions']}");return
    
    yield ("å¨œè¿¦", "ç”¨æ³•ï¼š#tree on/off/status");return
   
   # å¿«é€Ÿæ¨¡å‹ç³»ç»Ÿæ§åˆ¶æŒ‡ä»¤
   if u.strip().startswith("#quick"):
    command_parts = u.strip().split()
    
    if len(command_parts) == 1:
      yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹å‘½ä»¤ç”¨æ³•ï¼š\n#quick status - æŸ¥çœ‹çŠ¶æ€\n#quick config <api_key> <base_url> [model_name] - é…ç½®æ¨¡å‹\n#quick test - æµ‹è¯•åŠŸèƒ½\n#quick enable/disable - å¯ç”¨/ç¦ç”¨");return
    
    cmd = command_parts[1]
    
    if cmd == "status":
      if s.quick_model:
        stats = s.quick_model.get_stats()
        status_msg = f"âš¡ å¿«é€Ÿæ¨¡å‹çŠ¶æ€ï¼š\n"
        status_msg += f"â€¢ å¯ç”¨çŠ¶æ€ï¼š{'âœ… å·²å¯ç”¨' if stats['enabled'] else 'âŒ æœªå¯ç”¨'}\n"
        status_msg += f"â€¢ æ¨¡å‹åç§°ï¼š{stats['model_name']}\n"
        status_msg += f"â€¢ æ€»è°ƒç”¨æ¬¡æ•°ï¼š{stats['total_calls']}\n"
        status_msg += f"â€¢ å¿«é€Ÿæ¨¡å‹æˆåŠŸç‡ï¼š{stats['quick_success_rate']}\n"
        status_msg += f"â€¢ å¿«é€Ÿæ¨¡å‹ä½¿ç”¨ç‡ï¼š{stats['quick_usage_rate']}\n"
        status_msg += f"â€¢ èŠ‚çœæ—¶é—´ï¼š{stats['total_time_saved']}"
        yield ("å¨œè¿¦", status_msg);return
      else:
        yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–");return
    
    elif cmd == "config":
      if len(command_parts) < 4:
        yield ("å¨œè¿¦", "é…ç½®æ ¼å¼ï¼š#quick config <api_key> <base_url> [model_name]");return
      
      api_key = command_parts[2]
      base_url = command_parts[3]
      model_name = command_parts[4] if len(command_parts) > 4 else "qwen2.5-1.5b-instruct"
      
      if s.quick_model:
        new_config = {
          "enabled": True,
          "api_key": api_key,
          "base_url": base_url,
          "model_name": model_name
        }
        
        if s.quick_model.update_config(new_config):
          yield ("å¨œè¿¦", f"âš¡ å¿«é€Ÿæ¨¡å‹é…ç½®æ›´æ–°æˆåŠŸï¼\nâ€¢ APIå¯†é’¥ï¼š{api_key[:8]}...\nâ€¢ åœ°å€ï¼š{base_url}\nâ€¢ æ¨¡å‹ï¼š{model_name}");return
        else:
          yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹é…ç½®æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ä¿¡æ¯");return
      else:
        yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–");return
    
    elif cmd == "test":
      if s.quick_model and s.quick_model.is_enabled():
        try:
          # æµ‹è¯•å¿«é€Ÿå†³ç­–
          decision_result = await s.quick_model.quick_decision(
            "1+1ç­‰äºå¤šå°‘ï¼Ÿ", 
            decision_type="custom"
          )
          
          # æµ‹è¯•JSONæ ¼å¼åŒ–
          json_result = await s.quick_model.format_json(
            "æµ‹è¯•å†…å®¹ï¼šå¿«é€Ÿæ¨¡å‹æ­£å¸¸å·¥ä½œ",
            format_type="simple"
          )
          
          test_msg = f"âš¡ å¿«é€Ÿæ¨¡å‹æµ‹è¯•ç»“æœï¼š\n"
          test_msg += f"â€¢ å†³ç­–æµ‹è¯•ï¼š{decision_result['decision']} (æ¨¡å‹ï¼š{decision_result['model_used']}, è€—æ—¶ï¼š{decision_result['response_time']:.3f}s)\n"
          test_msg += f"â€¢ JSONæµ‹è¯•ï¼š{'âœ… æˆåŠŸ' if json_result['valid_json'] else 'âŒ å¤±è´¥'} (æ¨¡å‹ï¼š{json_result['model_used']}, è€—æ—¶ï¼š{json_result['response_time']:.3f}s)"
          
          yield ("å¨œè¿¦", test_msg);return
        except Exception as e:
          yield ("å¨œè¿¦", f"å¿«é€Ÿæ¨¡å‹æµ‹è¯•å¤±è´¥ï¼š{str(e)}");return
      else:
        yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹æœªå¯ç”¨æˆ–é…ç½®ä¸å®Œæ•´");return
    
    elif cmd == "enable":
      if s.quick_model:
        s.quick_model.config["enabled"] = True
        yield ("å¨œè¿¦", "âš¡ å¿«é€Ÿæ¨¡å‹å·²å¯ç”¨");return
      else:
        yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–");return
    
    elif cmd == "disable":
      if s.quick_model:
        s.quick_model.config["enabled"] = False
        s.quick_model.enabled = False
        yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹å·²ç¦ç”¨");return
      else:
        yield ("å¨œè¿¦", "å¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–");return
    
    else:
      yield ("å¨œè¿¦", f"æœªçŸ¥å‘½ä»¤ï¼š{cmd}");return
   
   # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯ç”¨æ ‘çŠ¶æ€è€ƒ
   tree_thinking_enabled = False
   if s.tree_thinking and s.tree_thinking.is_enabled:
    # æ£€æŸ¥é—®é¢˜å¤æ‚åº¦æ˜¯å¦éœ€è¦æ ‘çŠ¶æ€è€ƒ
    from thinking.config import COMPLEX_KEYWORDS
    question_lower = u.lower()
    complex_count = sum(1 for keyword in COMPLEX_KEYWORDS if keyword in question_lower)
    
    # é™ä½è§¦å‘é—¨æ§›ï¼š1ä¸ªå¤æ‚å…³é”®è¯æˆ–é—®é¢˜è¾ƒé•¿å³å¯è§¦å‘
    if complex_count >= 1 or len(u) > 50:
      tree_thinking_enabled = True
      logger.info(f"æ£€æµ‹åˆ°å¤æ‚é—®é¢˜ï¼Œå¯ç”¨æ ‘çŠ¶æ€è€ƒ - å¤æ‚å…³é”®è¯: {complex_count}, é•¿åº¦: {len(u)}")
      # è°ƒè¯•è¾“å‡ºåŒ¹é…çš„å…³é”®è¯
      matched_keywords = [keyword for keyword in COMPLEX_KEYWORDS if keyword in question_lower]
      logger.info(f"åŒ¹é…çš„å…³é”®è¯: {matched_keywords}")
    else:
      logger.info(f"æœªè§¦å‘æ ‘çŠ¶æ€è€ƒ - å¤æ‚å…³é”®è¯: {complex_count}, é•¿åº¦: {len(u)}")
   
   # å…¼å®¹å‡çº§æ¨¡å¼ä¼˜å…ˆåˆ¤æ–­
   if u.strip() == '#å¤å›­ç³»ç»Ÿå…¼å®¹å‡çº§':
    import subprocess, os, json
    LOG_DIR = 'logs'
    txt_files = [fn for fn in os.listdir(LOG_DIR) if fn.endswith('.txt') and fn[:4].isdigit() and fn[4] == '-' and fn[7] == '-']
    txt_files.sort()
    file_list_str = 'å‘ç°ä»¥ä¸‹å†å²å¯¹è¯æ—¥å¿—ï¼š\n' + '\n'.join([f'{idx+1}. {fn}' for idx, fn in enumerate(txt_files)]) + '\n' + '-'*40
    subprocess.run(['python', 'summer/summer_upgrade/compat_txt_to_faiss.py', 'list'])
    HISTORY_JSON = os.path.join('summer', 'summer_upgrade', 'history_dialogs.json')
    try:
        with open(HISTORY_JSON, encoding='utf-8') as f:
            all_chunks = json.load(f)
        total = len(all_chunks)
    except Exception:
        total = 0
    msg = f"{file_list_str}\nå…±{total}æ¡å†å²å¯¹è¯ï¼Œå·²é¢„çƒ­ç¼“å­˜è‡³summer/summer_upgrade/history_dialogs.json\nè¯·ç›´æ¥åœ¨å¯¹è¯æ¡†è¾“å…¥importå‘½ä»¤ï¼ˆå¦‚import allæˆ–import 1,3,5-8ï¼‰ä»¥å®Œæˆé€‰æ‹©æ€§å…¼å®¹ã€‚\nå¦‚éœ€é€€å‡ºå…¼å®¹æ¨¡å¼ï¼Œè¯·è¾“å…¥exitã€‚"
    s.compat_mode = True
    yield ("ç³»ç»Ÿ", msg)
    return
   # å…¼å®¹æ¨¡å¼åˆ¤æ–­
   if hasattr(s, 'compat_mode') and s.compat_mode:
    if u.strip().startswith('import '):
     import subprocess, sys
     args = u.strip().split(' ', 1)[1]
     yield ("ç³»ç»Ÿ", "æ­£åœ¨æ‰§è¡Œå…¼å®¹å¯¼å…¥ç¨‹åºï¼Œè¯·ç¨å€™...")
     result = subprocess.run(
         [sys.executable, 'summer/summer_upgrade/compat_txt_to_faiss.py', 'import', args],
         capture_output=True, text=True
     )
     output = result.stdout.strip() or result.stderr.strip()
     yield ("ç³»ç»Ÿ", f"å…¼å®¹å¯¼å…¥ç»“æœï¼š\n{output}")
     return
    elif u.strip() in ['exit', 'å®Œæˆ', 'é€€å‡ºå…¼å®¹']:
     s.compat_mode = False
     yield ("ç³»ç»Ÿ", "å·²é€€å‡ºç³»ç»Ÿå…¼å®¹å‡çº§æ¨¡å¼ï¼Œæ¢å¤æ­£å¸¸å¯¹è¯ã€‚")
     return
    else:
     yield ("ç³»ç»Ÿ", "å½“å‰ä¸ºç³»ç»Ÿå…¼å®¹å‡çº§æ¨¡å¼ï¼Œä»…æ”¯æŒimportæŒ‡ä»¤ã€‚å¦‚éœ€é€€å‡ºï¼Œè¯·è¾“å…¥exitã€‚")
     return
   print(f"è¯­éŸ³è½¬æ–‡æœ¬ç»“æŸï¼Œå¼€å§‹å‘é€ç»™GTPï¼š{now()}") # è¯­éŸ³è½¬æ–‡æœ¬ç»“æŸ/AIè¯·æ±‚å‰
   theme, level = s.get_theme_and_level(u)
   ctx = s.memory.build_context(u, k=5)
   
   # æ–°å¢ï¼šæ ‘çŠ¶æ€è€ƒå¤„ç†
   if tree_thinking_enabled:
    try:
      yield ("å¨œè¿¦", "ğŸŒ³ æ£€æµ‹åˆ°å¤æ‚é—®é¢˜ï¼Œå¯åŠ¨æ ‘çŠ¶å¤–ç½®æ€è€ƒç³»ç»Ÿ...")
      
      # ä½¿ç”¨æ ‘çŠ¶æ€è€ƒå¼•æ“å¤„ç†
      thinking_result = await s.tree_thinking.think_deeply(u)
      
      if thinking_result and "answer" in thinking_result:
        # è¾“å‡ºæ€è€ƒè¿‡ç¨‹ä¿¡æ¯
        process_info = thinking_result.get("thinking_process", {})
        difficulty = process_info.get("difficulty", {})
        
        yield ("å¨œè¿¦", f"\nğŸ§  æ·±åº¦æ€è€ƒå®Œæˆï¼š")
        yield ("å¨œè¿¦", f"â€¢ é—®é¢˜éš¾åº¦ï¼š{difficulty.get('difficulty', 'N/A')}/5")
        yield ("å¨œè¿¦", f"â€¢ æ€è€ƒè·¯çº¿ï¼š{process_info.get('routes_generated', 0)}æ¡ â†’ {process_info.get('routes_selected', 0)}æ¡")
        yield ("å¨œè¿¦", f"â€¢ å¤„ç†æ—¶é—´ï¼š{process_info.get('processing_time', 0):.2f}ç§’")
        
        # è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
        yield ("å¨œè¿¦", f"\n{thinking_result['answer']}")
        
        # ä¿å­˜è®°å½•å’Œè®°å¿†
        final_answer = thinking_result['answer']
        s.messages+=[{"role":"user","content":u},{"role":"assistant","content":final_answer}]
        s.save_log(u, final_answer)
        
        if not s.dev_mode:
          faiss_add([{
              'text': final_answer,
              'role': 'ai',
              'time': get_current_datetime(),
              'file': 'conversation.txt',
              'theme': theme
          }])
        
        s.memory.add_memory({'role':'user','text':u,'time':get_current_datetime(),'file':datetime.now().strftime('%Y-%m-%d')+'.txt','theme':theme}, level=level)
        s.memory.add_memory({'role':'ai','text':final_answer,'time':get_current_datetime(),'file':datetime.now().strftime('%Y-%m-%d')+'.txt','theme':theme}, level=level)
        
        # æƒé‡è°ƒæ•´
        s.memory.adjust_weights_periodically()
        return
      else:
        yield ("å¨œè¿¦", "ğŸŒ³ æ ‘çŠ¶æ€è€ƒå¤„ç†å¼‚å¸¸ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼...")
        
    except Exception as e:
      logger.error(f"æ ‘çŠ¶æ€è€ƒå¤„ç†å¤±è´¥: {e}")
      yield ("å¨œè¿¦", f"ğŸŒ³ æ ‘çŠ¶æ€è€ƒç³»ç»Ÿå‡ºé”™ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼: {str(e)}")
   
   # æ·»åŠ handoffæç¤ºè¯
   system_prompt = f"{RECOMMENDED_PROMPT_PREFIX}\n{s.get_current_system_prompt()}"
   sysmsg={"role":"system","content":f"å†å²ç›¸å…³å†…å®¹å¬å›:\n{ctx}\n\n{system_prompt.format(available_mcp_services=s.mcp.format_available_services())}"} if ctx else {"role":"system","content":system_prompt.format(available_mcp_services=s.mcp.format_available_services())}
   msgs=[sysmsg] if sysmsg else[]
   msgs+=s.messages[-20:]+[{"role":"user","content":u}]
   
   print(f"GTPè¯·æ±‚å‘é€ï¼š{now()}") # AIè¯·æ±‚å‰
   # æµå¼è¾“å‡º
   a = ''
   resp = await s.async_client.chat.completions.create(model=DEEPSEEK_MODEL,messages=msgs,temperature=TEMPERATURE,max_tokens=MAX_TOKENS,stream=True)
   async for chunk in resp:
    if chunk.choices and chunk.choices[0].delta.content:
     a+=chunk.choices[0].delta.content
     yield ("å¨œè¿¦",chunk.choices[0].delta.content) # æµå¼yieldä¸åŠ æ¢è¡Œ
   print(f"GTPè¿”å›æ•°æ®ï¼š{now()}") # AIè¿”å›
   
   # æ–°å¢ï¼šè‡ªåŠ¨è§£æplanç»“æ„å¹¶åˆ†æ­¥æ‰§è¡Œ
   try:
    resp_json = json.loads(a)
    if "plan" in resp_json:
     plan = resp_json["plan"]
     steps = plan.get("steps", [])
     context = {}
     for idx, step in enumerate(steps):
      desc = step.get("desc", "")
      action = step.get("action")
      if action and "agent" in action:
       agent = action["agent"]
       params = action.get("params", {})
       # è‡ªåŠ¨æ£€æµ‹å¹¶è½¬æ¢shellå‘½ä»¤æ ¼å¼
       if agent == "shell" and isinstance(params.get("command"), str):
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²å‘½ä»¤ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºpowershellæ•°ç»„
        old_cmd = params["command"]
        params["command"] = ["powershell", "-Command", old_cmd]
        yield ("å¨œè¿¦", f"[è­¦å‘Š] ç¬¬{idx+1}æ­¥å‘½ä»¤ä¸ºå­—ç¬¦ä¸²ï¼Œå·²è‡ªåŠ¨è½¬æ¢ä¸ºpowershellæ•°ç»„ï¼š{params['command']}")
       # æ”¯æŒä¸Šä¸‹æ–‡ä¼ é€’
       params["context"] = context
       yield ("å¨œè¿¦", f"æ­£åœ¨æ‰§è¡Œç¬¬{idx+1}æ­¥ï¼š{desc}ï¼ˆagent: {agent}ï¼‰")
       try:
        result = await s.mcp.handoff(agent, params)
        # æ–°å¢ï¼šåªæå–æ ¸å¿ƒå†…å®¹ï¼Œé¿å…å‰ç«¯æ˜¾ç¤ºå®Œæ•´json
        try:
            result_json = json.loads(result)
            msg = result_json.get("data", {}).get("content") or result_json.get("message") or str(result_json.get("status"))
        except Exception:
            msg = str(result)
        yield ("å¨œè¿¦", f"ç¬¬{idx+1}æ­¥æ‰§è¡Œç»“æœï¼š{msg}")
        context[f"step_{idx+1}_result"] = result
       except Exception as e:
        yield ("å¨œè¿¦", f"ç¬¬{idx+1}æ­¥æ‰§è¡Œå¤±è´¥ï¼š{e}")
      else:
       yield ("å¨œè¿¦", f"ç¬¬{idx+1}æ­¥ï¼š{desc}ï¼ˆæ— éœ€è‡ªåŠ¨æ‰§è¡Œï¼‰")
     yield ("å¨œè¿¦", f"æ‰€æœ‰åˆ†æ­¥æ‰§è¡Œå·²å®Œæˆã€‚")
     return
   except Exception as e:
    pass # éplanç»“æ„æˆ–è§£æå¤±è´¥ï¼Œç»§ç»­åŸæœ‰æµç¨‹
   
   # æ£€æŸ¥LLMæ˜¯å¦å»ºè®®handoff
   if "[handoff]" in a:
    service = a.split("[handoff]")[1].strip().split()[0]
    yield ("å¨œè¿¦",(await s.mcp.handoff(
     service,
     task={
       "messages": s.messages[-5:],
       "query": u,
       "url": extract_url(u),
       "source": "llm",
       "input_type": "browser"
     }
    )));return
   
   s.messages+=[{"role":"user","content":u},{"role":"assistant","content":a}]
   s.save_log(u,a)
   if not s.dev_mode:
    faiss_add([{
        'text': a,
        'role': 'ai',
        'time': get_current_datetime(),
        'file': 'conversation.txt',
        'theme': theme  # ç¡®ä¿themeå­—æ®µå†™å…¥meta
    }])
   s.memory.add_memory({'role':'user','text':u,'time':get_current_datetime(),'file':datetime.now().strftime('%Y-%m-%d')+'.txt','theme':theme}, level=level)
   s.memory.add_memory({'role':'ai','text':a,'time':get_current_datetime(),'file':datetime.now().strftime('%Y-%m-%d')+'.txt','theme':theme}, level=level)
   # æ–°å¢ï¼šæ”¯æŒç”¨æˆ·é€šè¿‡#important <å†…å®¹ç‰‡æ®µ>å‘½ä»¤æ ‡è®°è®°å¿†ä¸ºé‡è¦ï¼ˆå•æ¡æˆ–æ‰¹é‡æ™ºèƒ½åˆ¤æ–­ï¼‰
   if u.strip().startswith('#important'):
    mark_text = u.strip()[10:].strip()
    if not mark_text:
     yield ("å¨œè¿¦","è¯·åœ¨#importantåè¾“å…¥è¦æ ‡è®°çš„é‡è¦å†…å®¹ç‰‡æ®µã€‚");return
    # æ¨¡ç³Šå¬å›å¤šæ¡ç›¸å…³è®°å¿†
    recall = s.memory.fuzzy_recall(mark_text, k=5)  # kå€¼å¯æ ¹æ®éœ€è¦è°ƒæ•´
    if recall:
     keys = [item.get('key') for item in recall if 'key' in item]
     if len(keys) == 1:
      s.memory.mark_important(keys[0])
      yield ("å¨œè¿¦",f"å·²å°†ç›¸å…³è®°å¿†ç‰‡æ®µæ ‡è®°ä¸ºé‡è¦ï¼š{recall[0].get('text','')}");return
     else:
      updated = s.memory.mark_important_batch(keys)
      preview = "\n".join([f"{i+1}.{item.get('text','')[:30]}" for i,item in enumerate(recall)])
      yield ("å¨œè¿¦",f"å·²æ‰¹é‡æ ‡è®°{updated}æ¡ç›¸å…³è®°å¿†ä¸ºé‡è¦ï¼š\n{preview}");return
    else:
     yield ("å¨œè¿¦","æœªæ‰¾åˆ°ç›¸å…³è®°å¿†ï¼Œæ— æ³•æ ‡è®°ã€‚");return
   # æ¯20è½®åŠ¨æ€æ‰¹é‡è¡°å‡æƒé‡
   s.memory.adjust_weights_periodically()
   return
  except Exception as e:
   import sys, traceback;traceback.print_exc(file=sys.stderr)
   yield ("å¨œè¿¦",f"[MCPå¼‚å¸¸]: {e}");return

 def set_personality(s, personality_code, personality_config):
     """è®¾ç½®å¨œè¿¦çš„æ€§æ ¼æ¨¡å¼"""
     s.current_personality = personality_code
     s.personality_config = personality_config
     logger.info(f"æ€§æ ¼å·²åˆ‡æ¢ä¸º: {personality_code} - {personality_config.get('name', '')}")
 
 def get_current_system_prompt(s):
     """è·å–å½“å‰çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆåŸºäºæ€§æ ¼ï¼‰"""
     if s.current_personality == "DEFAULT":
         return s.base_system_prompt
     elif 'prompt' in s.personality_config:
         return s.personality_config['prompt']
     else:
         return s.base_system_prompt

 async def get_response(s, prompt: str, temperature: float = 0.7) -> str:
     """ä¸ºæ ‘çŠ¶æ€è€ƒç³»ç»Ÿæä¾›APIè°ƒç”¨æ¥å£"""
     try:
         response = await s.async_client.chat.completions.create(
             model=DEEPSEEK_MODEL,
             messages=[{"role": "user", "content": prompt}],
             temperature=temperature,
             max_tokens=MAX_TOKENS
         )
         return response.choices[0].message.content
     except Exception as e:
         logger.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
         return f"APIè°ƒç”¨å‡ºé”™: {str(e)}"

async def process_user_message(s,msg):
    if vcfg.ENABLED and not msg: #æ— æ–‡æœ¬è¾“å…¥æ—¶å¯åŠ¨è¯­éŸ³è¯†åˆ«
        async for text in s.voice.stt_stream():
            if text:msg=text;break
    return await s.process(msg)

async def send_ai_message(s,msg):
    if vcfg.ENABLED: #å¯ç”¨è¯­éŸ³æ—¶è½¬æ¢ä¸ºè¯­éŸ³
        async for _ in s.voice.tts_stream(msg):pass
    return msg 